{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "sns.set_theme()\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.model_selection import cross_val_predict, GridSearchCV\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"data/train.csv\")\n",
    "test = pd.read_csv(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>290</th>\n",
       "      <th>291</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.098</td>\n",
       "      <td>2.165</td>\n",
       "      <td>0.681</td>\n",
       "      <td>-0.614</td>\n",
       "      <td>1.309</td>\n",
       "      <td>-0.455</td>\n",
       "      <td>-0.236</td>\n",
       "      <td>0.276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867</td>\n",
       "      <td>1.347</td>\n",
       "      <td>0.504</td>\n",
       "      <td>-0.649</td>\n",
       "      <td>0.672</td>\n",
       "      <td>-2.097</td>\n",
       "      <td>1.051</td>\n",
       "      <td>-0.414</td>\n",
       "      <td>1.038</td>\n",
       "      <td>-1.065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.081</td>\n",
       "      <td>-0.973</td>\n",
       "      <td>-0.383</td>\n",
       "      <td>0.326</td>\n",
       "      <td>-0.428</td>\n",
       "      <td>0.317</td>\n",
       "      <td>1.172</td>\n",
       "      <td>0.352</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.165</td>\n",
       "      <td>-1.695</td>\n",
       "      <td>-1.257</td>\n",
       "      <td>1.359</td>\n",
       "      <td>-0.808</td>\n",
       "      <td>-1.624</td>\n",
       "      <td>-0.458</td>\n",
       "      <td>-1.099</td>\n",
       "      <td>-0.936</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.523</td>\n",
       "      <td>-0.089</td>\n",
       "      <td>-0.348</td>\n",
       "      <td>0.148</td>\n",
       "      <td>-0.022</td>\n",
       "      <td>0.404</td>\n",
       "      <td>-0.023</td>\n",
       "      <td>-0.172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.263</td>\n",
       "      <td>-1.222</td>\n",
       "      <td>0.726</td>\n",
       "      <td>1.444</td>\n",
       "      <td>-1.165</td>\n",
       "      <td>-1.544</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.800</td>\n",
       "      <td>-1.211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.067</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>0.392</td>\n",
       "      <td>-1.637</td>\n",
       "      <td>-0.446</td>\n",
       "      <td>-0.725</td>\n",
       "      <td>-1.035</td>\n",
       "      <td>0.834</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.404</td>\n",
       "      <td>0.640</td>\n",
       "      <td>-0.595</td>\n",
       "      <td>-0.966</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.467</td>\n",
       "      <td>-0.562</td>\n",
       "      <td>-0.254</td>\n",
       "      <td>-0.533</td>\n",
       "      <td>0.238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.347</td>\n",
       "      <td>-0.831</td>\n",
       "      <td>0.511</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>1.225</td>\n",
       "      <td>1.594</td>\n",
       "      <td>0.585</td>\n",
       "      <td>1.509</td>\n",
       "      <td>...</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.134</td>\n",
       "      <td>2.415</td>\n",
       "      <td>-0.996</td>\n",
       "      <td>-1.006</td>\n",
       "      <td>1.378</td>\n",
       "      <td>1.246</td>\n",
       "      <td>1.478</td>\n",
       "      <td>0.428</td>\n",
       "      <td>0.253</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 302 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target      0      1      2      3      4      5      6      7  ...  \\\n",
       "0   0     1.0 -0.098  2.165  0.681 -0.614  1.309 -0.455 -0.236  0.276  ...   \n",
       "1   1     0.0  1.081 -0.973 -0.383  0.326 -0.428  0.317  1.172  0.352  ...   \n",
       "2   2     1.0 -0.523 -0.089 -0.348  0.148 -0.022  0.404 -0.023 -0.172  ...   \n",
       "3   3     1.0  0.067 -0.021  0.392 -1.637 -0.446 -0.725 -1.035  0.834  ...   \n",
       "4   4     1.0  2.347 -0.831  0.511 -0.021  1.225  1.594  0.585  1.509  ...   \n",
       "\n",
       "     290    291    292    293    294    295    296    297    298    299  \n",
       "0  0.867  1.347  0.504 -0.649  0.672 -2.097  1.051 -0.414  1.038 -1.065  \n",
       "1 -0.165 -1.695 -1.257  1.359 -0.808 -1.624 -0.458 -1.099 -0.936  0.973  \n",
       "2  0.013  0.263 -1.222  0.726  1.444 -1.165 -1.544  0.004  0.800 -1.211  \n",
       "3 -0.404  0.640 -0.595 -0.966  0.900  0.467 -0.562 -0.254 -0.533  0.238  \n",
       "4  0.898  0.134  2.415 -0.996 -1.006  1.378  1.246  1.478  0.428  0.253  \n",
       "\n",
       "[5 rows x 302 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test set is much more bigger than train set, and the latter is quite small so it will be challenge to create a model which will generalize well.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set samples: 250\n",
      "Train set features: 302\n"
     ]
    }
   ],
   "source": [
    "print(\"Train set samples:\", train.shape[0])\n",
    "print(\"Train set features:\", train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set samples: 19750\n",
      "Test set features: 301\n"
     ]
    }
   ],
   "source": [
    "print(\"Test set samples:\", test.shape[0])\n",
    "print(\"Test set features:\", test.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEJCAYAAAB/pOvWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAcWUlEQVR4nO3df3AU9f3H8dflB0GaOLVxDzAyzLQCUQah1hmM0AQcTIIkWC6MEhXwBwNUi4gtBZJIpmIEEcRWh+nQOji1OBpRS0xpoBqJQhTbDEJBVCokAsXkEipwQH7e5/uH9L7iYnKJub2Eez5mmLnd273P+01m9nW3e/s5lzHGCACAr4kKdwEAgJ6HcAAA2BAOAAAbwgEAYEM4AABsCAcAgA3hAACwiQl3Ad3lv/89Lb+/87dsJCbGq6HBF4KKei56jgz0HBm62nNUlEuXXfa9b33+ogkHv990KRz+t2+koefIQM+RIRQ9c1oJAGBDOAAAbAgHAIAN4QAAsAlpOPh8PmVlZenIkSOSpF27dum2227TpEmT9PDDD6u5uVmStH//fnk8HmVkZCg/P1+tra2hLAsA0IGQhcPu3buVm5ur6upqSV8Fxbx58/Too4/qr3/9qyRp48aNkqSFCxdq6dKl2rJli4wxKi4uDlVZAIAghCwciouLVVhYKLfbLUnasWOHRo0apeTkZElSQUGBbr75Zh09elSNjY0aNWqUJMnj8aisrCxUZQEAghCy+xyKiorOW66pqVG/fv20YMECHTx4UNddd50WL16sjz76SJZlBbazLEu1tbWdHi8xMb7LtVpWQpf37a3oOTLQc+i0tPoVGxP+y7Ytrf6Q9OzYTXBtbW3avn27Xn75ZV1xxRXKz8/XunXrdOONN8rlcgW2M8actxyshgZfl24EsawEeb2nOr1fb0bPkYGeQz/Wwt9WODJWe56cn9alnqOiXO2+qXYs9i6//HKNHDlSgwYNUnR0tCZOnKg9e/ZowIAB8nq9ge3q6+sDp6IAAOHhWDiMHTtW+/bt07FjxyRJb7/9toYPH66kpCTFxcWpqqpKkrRp0yalpqY6VRYA4AIcO600cOBAPfroo5o7d66ampp09dVXa9GiRZKkVatWqaCgQD6fT8OHD9eMGTOcKgsAcAEhD4fy8vLA43HjxmncuHG2bZKTkwNfawUAhF/4L7UDAHocwgEAYEM4AABsCAcAgA3hAACwIRwAADaEAwDAhnAAANgQDgAAG8IBAGBDOAAAbAgHAIAN4QAAsCEcAAA2hAMAwIZwAADYhDQcfD6fsrKydOTIkfPW//nPf9b06dMDy/v375fH41FGRoby8/PV2toayrIAAB0IWTjs3r1bubm5qq6uPm/9v//9b61bt+68dQsXLtTSpUu1ZcsWGWNUXFwcqrIAAEEIWTgUFxersLBQbrc7sK65uVlLly7Vgw8+GFh39OhRNTY2atSoUZIkj8ejsrKyUJUFAAhCyH5DuqioyLZu9erVysnJ0ZVXXhlYV1dXJ8uyAsuWZam2tjZUZQEAghCycPimHTt26NixY1qyZIl27twZWO/3++VyuQLLxpjzloOVmBjf5dosK6HL+/ZW9BwZ6Dm0YmMdO4S2KxQ9O9ZZaWmpDhw4oFtvvVVnzpxRfX29HnroIS1cuFBerzewXX19/XmnooLV0OCT3286vZ9lJcjrPdXp/Xozeo4M9Bz6sVpaesaXZ7rSc1SUq9031Y6Fw/LlywOPd+7cqWeffVZPP/20JCkuLk5VVVX6yU9+ok2bNik1NdWpsgAAF9AjPhOtWrVKBQUF8vl8Gj58uGbMmBHukgAgooU8HMrLy23rRo8erdGjRweWk5OTtXHjxlCXAgAIEndIAwBsCAcAgA3hAACwIRwAADaEAwDAhnAAANgQDgAAG8IBAGBDOAAAbAgHAIAN4QAAsCEcAAA2hAMAwIZwAADYEA4AABvCAQBgQzgAAGxCGg4+n09ZWVk6cuSIJOnll19WVlaWsrOztWTJEjU3N0uS9u/fL4/Ho4yMDOXn56u1tWf8aDcARKqQhcPu3buVm5ur6upqSdKhQ4f03HPP6aWXXlJJSYn8fr9efPFFSdLChQu1dOlSbdmyRcYYFRcXh6osAEAQQhYOxcXFKiwslNvtliT16dNHhYWFio+Pl8vl0tChQ/Wf//xHR48eVWNjo0aNGiVJ8ng8KisrC1VZAIAgxITqhYuKis5bTkpKUlJSkiTp+PHj2rBhg5YvX666ujpZlhXYzrIs1dbWhqosAEAQQhYO36a2tlazZs1STk6ORo8eraqqKrlcrsDzxpjzloOVmBjf5ZosK6HL+/ZW9BwZ6Dm0YmMdP4ReUCh6drSzzz77TLNmzdL06dN17733SpIGDBggr9cb2Ka+vj5wKqozGhp88vtNp/ezrAR5vac6vV9vRs+RgZ5DP1ZLS8/48kxXeo6KcrX7ptqxr7L6fD7dd999mj9/fiAYpK9ON8XFxamqqkqStGnTJqWmpjpVFgDgAhz75LBx40bV19dr/fr1Wr9+vSTppptu0vz587Vq1SoVFBTI5/Np+PDhmjFjhlNlAQAuIOThUF5eLkm6++67dffdd19wm+TkZG3cuDHUpQAAgsQd0gAAG8IBAGBDOAAAbAgHAIAN4QAAsCEcAAA2hAMAwIZwAADYEA4AABvCAQBgQzgAAGwIBwCADeEAALAhHAAANoQDAMCGcAAA2BAOAACbkIaDz+dTVlaWjhw5IkmqrKxUdna20tPTtWbNmsB2+/fvl8fjUUZGhvLz89Xa2jN+tBsAIlXIwmH37t3Kzc1VdXW1JKmxsVF5eXlau3atNm/erL1796qiokKStHDhQi1dulRbtmyRMUbFxcWhKgsAEISQhUNxcbEKCwvldrslSXv27NHgwYM1aNAgxcTEKDs7W2VlZTp69KgaGxs1atQoSZLH41FZWVmoygIABCEmVC9cVFR03nJdXZ0sywosu91u1dbW2tZblqXa2tpQlQUACELIwuGb/H6/XC5XYNkYI5fL9a3rOysxMb7LtVlWQpf37a3oOTLQc2jFxjp2CG1XKHp2rLMBAwbI6/UGlr1er9xut219fX194FRUZzQ0+OT3m07vZ1kJ8npPdXq/3oyeIwM9h36slpae8eWZrvQcFeVq9021Y19lHTlypA4dOqSamhq1tbWptLRUqampSkpKUlxcnKqqqiRJmzZtUmpqqlNlAQAuwLFPDnFxcVqxYoXmzZunpqYmpaWlKTMzU5K0atUqFRQUyOfzafjw4ZoxY4ZTZQEALiDk4VBeXh54nJKSopKSEts2ycnJ2rhxY6hLAQAEiTukAQA2hAMAwCaocMjLy7Ote/DBB7u9GABAz9DuNYfCwkLV1taqqqpKx48fD6xvbW3V4cOHQ14cACA82g2HqVOn6sCBA/rkk0+UkZERWB8dHR2Y7gIAcPFpNxxGjBihESNG6MYbb9SAAQOcqgkAEGZBfZX12LFjWrhwoU6cOCFj/v8u5DfeeCNkhQEAwieocFi6dKk8Ho+uueaaLs17BADoXYIKh5iYGN1zzz2hriUsWlr9PWJysqbmVp08cTbcZQCApCDDYciQIfrkk080bNiwUNfjuNiYKC38bUW4y9CT89PCXQIABAQVDocPH1ZOTo6uuOIKxcXFBdZzzQEALk5BhcOCBQtCXQcAoAcJKhyGDh0a6joAAD1IUOFwww03yOVynfcrbZZl6Z133glpcQCA8AgqHD7++OPA4+bmZpWWlurQoUMhKwoAEF6dnpW1T58+8ng82rFjRyjqAQD0AEF9cvjyyy8Dj40x2rt3r06ePBmqmgAAYdbpaw6SlJiYqPz8/C4PumnTJq1bt06SlJqaqkWLFqmyslLLly9XU1OTJk6cyDekACCMOn3N4bs6e/asioqKVFZWpksvvVS5ubkqLy/Xo48+qhdeeEEDBw7UnDlzVFFRobQ0bgwDgHAI6pqD3+/XH/7wB02fPl25ubl69tln1dra2qUB29ra5Pf7dfbsWbW2tqq1tVXx8fEaPHiwBg0apJiYGGVnZ6usrKxLrw8A+O6CCofVq1fr/fff18yZM3XPPfdo165dWrlyZZcGjI+P1/z58zVx4kSlpaUpKSlJdXV1siwrsI3b7VZtbW2XXh8A8N0FdVrp3Xff1auvvqrY2FhJ0rhx4zR58uQL/nxoRz7++GO9+uqrevvtt5WQkKBf/epXqq6uPm+216/fTxGsxMT4TtfyP7GxQf03hJyTEwD2hMkGnUbPkcHJni/mY0dQnRljAsEgffV11q8vd8b27duVkpKixMRESZLH49Fzzz2n6OjowDZer1dut7tTr9vQ4JPfbzre8BssK0EtLV07RdbdvN5TjoxjWQmOjdVT0HNkcLLn3n7siIpytfumOqjTSsnJyXr88cf1+eef6/Dhw3r88ce7PKVGcnKyKisrdebMGRljVF5erpEjR+rQoUOqqalRW1ubSktLlZqa2qXXBwB8d0F9cigsLNRjjz2madOmye/366c//akeeeSRLg04duxYffTRR/J4PIqNjdWIESM0b948jRkzRvPmzVNTU5PS0tKUmZnZpdcHAHx37YZDc3OzHnnkEU2YMEErVqyQJM2ePVvR0dGKj+/6Of7Zs2dr9uzZ561LSUlRSUlJl18TANB92j2t9Lvf/U4+n0/XXXddYN2yZct08uRJPfPMMyEvDgAQHu2Gw7Zt27R69erAxWNJ6t+/v1auXKk333wz5MUBAMKj3XCIjY1V3759bevj4+PVp0+fkBUFAAivdsMhKipKPp/Ptt7n83X5DmkAQM/XbjhkZWWpoKBAZ86cCaw7c+aMCgoKlJ6eHvLiAADh0W44zJw5UwkJCRozZoxuu+02TZ06VWPGjNGll16qBx54wKkaAQAOa/errFFRUVq2bJnmzp2rffv2KSoqStdee22n714GAPQuQd0El5SUpKSkpFDXAgDoITr9M6EAgIsf4QAAsCEcAAA2hAMAwIZwAADYEA4AABvCAQBgQzgAAGwIBwCATVjCoby8XB6PRxMnTtRjjz0mSaqsrFR2drbS09O1Zs2acJQFADjH8XA4fPiwCgsLtXbtWpWUlOijjz5SRUWF8vLytHbtWm3evFl79+5VRUWF06UBAM5xPBz+/ve/65ZbbtGAAQMUGxurNWvW6JJLLtHgwYM1aNAgxcTEKDs7W2VlZU6XBgA4J6iJ97pTTU2NYmNjNXfuXB07dkzjxo3TkCFDZFlWYBu3263a2lqnSwMAnON4OLS1temf//ynXnjhBfXr108///nP1bdvX7lcrsA2xpjzloORmBjf5ZpiYx3/b7ggy0q4KMfqKeg5MjjZ88V87HC8s8svv1wpKSn6wQ9+IEmaMGGCysrKFB0dHdjG6/V2+jcjGhp88vtNp+uxrAS1tPSMnzz1ek85Mo5lJTg2Vk9Bz5HByZ57+7EjKsrV7ptqx685jB8/Xtu3b9fJkyfV1tamd999V5mZmTp06JBqamrU1tam0tJSpaamOl0aAOAcxz85jBw5UrNmzdIdd9yhlpYWjRkzRrm5ufrhD3+oefPmqampSWlpacrMzHS6NADAOWE5YTZ16lRNnTr1vHUpKSkqKSkJRzkAgG/gDmkAgA3hAACwIRwAADaEAwDAhnAAANgQDgAAG8IBAGBDOAAAbAgHAIAN4QAAsCEcAAA2hAMAwIZwAADYEA4AABvCAQBgQzgAAGwIBwCATVjD4YknntDixYslSZWVlcrOzlZ6errWrFkTzrIAIOKFLRzee+89vf7665KkxsZG5eXlae3atdq8ebP27t2rioqKcJUGABEvLOHw5Zdfas2aNZo7d64kac+ePRo8eLAGDRqkmJgYZWdnq6ysLBylAQAkxYRj0KVLl2rBggU6duyYJKmurk6WZQWed7vdqq2t7dRrJibGd7me2Niw/DfYWFbCRTlWT0HPkcHJni/mY4fjnb3yyisaOHCgUlJS9Nprr0mS/H6/XC5XYBtjzHnLwWho8MnvN52ux7IS1NLS2un9QsHrPeXIOJaV4NhYPQU9RwYne+7tx46oKFe7b6odD4fNmzfL6/Xq1ltv1YkTJ3TmzBkdPXpU0dHRgW28Xq/cbrfTpQEAznE8HNavXx94/Nprr+mDDz7Qb37zG6Wnp6umpkZXXnmlSktLlZOT43RpAIBzesQJs7i4OK1YsULz5s1TU1OT0tLSlJmZGe6yACBihTUcPB6PPB6PJCklJUUlJSXhLAcAcA53SAMAbAgHAIAN4QAAsCEcAAA2hAMAwIZwAADYEA4AABvCAQBgQzgAAGwIBwCADeEAALAhHAAANoQDAMCGcAAA2BAOAAAbwgEAYEM4AABswhIOzz77rCZNmqRJkyZp5cqVkqTKykplZ2crPT1da9asCUdZAIBzHA+HyspKbd++Xa+//rr+8pe/aN++fSotLVVeXp7Wrl2rzZs3a+/evaqoqHC6NADAOY6Hg2VZWrx4sfr06aPY2Fj96Ec/UnV1tQYPHqxBgwYpJiZG2dnZKisrc7o0AMA5MU4POGTIkMDj6upq/e1vf9Ndd90ly7IC691ut2prazv1uomJ8V2uKTbW8f+GC7KshItyrJ6CniODkz1fzMeOsHV24MABzZkzR7/+9a8VHR2t6urqwHPGGLlcrk69XkODT36/6XQdlpWglpbWTu8XCl7vKUfGsawEx8bqKeg5MjjZc28/dkRFudp9Ux2WC9JVVVW6++679ctf/lJTpkzRgAED5PV6A897vV653e5wlAYAUBjC4dixY3rggQe0atUqTZo0SZI0cuRIHTp0SDU1NWpra1NpaalSU1OdLg0AcI7jp5Wee+45NTU1acWKFYF106ZN04oVKzRv3jw1NTUpLS1NmZmZTpcGADjH8XAoKChQQUHBBZ8rKSlxuBoAwIVwhzQAwIZwAADYEA4AABvCAQBgQzgAAGwIBwCADeEAALAhHAAANoQDAMCGcAAA2BAOAAAbwgEAYEM4AABsCAcAgA3hAACwIRwAADaEAwDApkeFwxtvvKFbbrlF6enp2rBhQ7jLAYCI5fjPhH6b2tparVmzRq+99pr69OmjadOmafTo0brqqqvCXRoARJweEw6VlZW64YYb9P3vf1+SlJGRobKyMv3iF78Iav+oKFeXx74sIa7L+3an79JDTx6rp6DnyOBkz7352NHRPj0mHOrq6mRZVmDZ7XZrz549Qe9/2WXf6/LYeffe0OV9u1NiYvxFOVZPQc+RwcmeL+ZjR4+55uD3++Vy/X+SGWPOWwYAOKfHhMOAAQPk9XoDy16vV263O4wVAUDk6jHhcOONN+q9997T8ePHdfbsWW3dulWpqanhLgsAIlKPuebQv39/LViwQDNmzFBLS4umTp2qa6+9NtxlAUBEchljTLiLAAD0LD3mtBIAoOcgHAAANoQDAMCGcAAA2ERMOHQ0qd/+/fvl8XiUkZGh/Px8tba2hqHK7tVRz2+++aZuvfVWTZ48Wffff79OnDgRhiq7V7CTN27btk033XSTg5WFTkc9Hzx4UNOnT9fkyZN13333RcTfed++fcrJydHkyZM1Z84cnTx5MgxVdi+fz6esrCwdOXLE9lxIjl8mAnzxxRdm/Pjx5r///a85ffq0yc7ONgcOHDhvm0mTJpldu3YZY4xZsmSJ2bBhQxgq7T4d9Xzq1CkzZswY88UXXxhjjHn66afNsmXLwlVutwjm72yMMV6v12RmZprx48eHocru1VHPfr/fpKenm4qKCmOMMU8++aRZuXJluMrtFsH8nXNzc822bduMMcYsX77cPPXUU+Eotdt8+OGHJisrywwfPtwcPnzY9nwojl8R8cnh65P69evXLzCp3/8cPXpUjY2NGjVqlCTJ4/Gc93xv1FHPLS0tKiwsVP/+/SVJw4YN07Fjx8JVbrfoqOf/KSgoCHpCx56uo5737dunfv36BW4onTt3ru68885wldstgvk7+/1+nT59WpJ09uxZ9e3bNxyldpvi4mIVFhZecNaIUB2/IiIcLjSpX21t7bc+b1nWec/3Rh31fNlll+nmm2+WJDU2NmrdunWaMGGC43V2p456lqQ//elPuuaaazRy5EinywuJjnr+/PPPdfnllysvL09TpkxRYWGh+vXrF45Su00wf+fFixeroKBAY8eOVWVlpaZNm+Z0md2qqKhI119//QWfC9XxKyLCoaNJ/S7GSf+C7enUqVOaPXu2kpOTNWXKFCdL7HYd9fzpp59q69atuv/++8NRXkh01HNra6s++OAD5ebm6vXXX9egQYO0YsWKcJTabTrqubGxUfn5+Xr++ee1fft23XHHHVq0aFE4SnVEqI5fEREOHU3q983n6+vre/2kf8FMZFhXV6c77rhDw4YNU1FRkdMldruOei4rK5PX61VOTo5mz54d6L8366hny7I0ePBgjRgxQpKUlZXVqanwe6KOev70008VFxcXmH7n9ttv1wcffOB4nU4J1fErIsKho0n9kpKSFBcXp6qqKknSpk2bev2kfx313NbWprlz52rixInKz8/v9Z+UpI57fvDBB7VlyxZt2rRJ69atk9vt1osvvhjGir+7jnr+8Y9/rOPHj+vjjz+WJJWXl2v48OHhKrdbdNTz4MGD9cUXX+jgwYOSpLfeeisQjhejkB2/vvMl7V6ipKTETJo0yaSnp5t169YZY4yZNWuW2bNnjzHGmP3795ucnByTkZFhHn74YdPU1BTOcrtFez1v3brVDBs2zEyePDnwLy8vL8wVf3cd/Z3/5/DhwxfFt5WM6bjnDz/80OTk5JhbbrnF3Hvvvaa+vj6c5XaLjnretm2byc7ONllZWWbmzJnm888/D2e53Wb8+PGBbyuF+vjFxHsAAJuIOK0EAOgcwgEAYEM4AABsCAcAgA3hAACwIRyAINx77706fvx4yMd55ZVX2p1NFnAK4QAEYceOHY6MU1VVpcbGRkfGAtoTE+4CgJ5uyZIlkqSZM2fqvvvu00svvaTm5mYdP35cP/vZz/TQQw9p586dKioqUr9+/XT69Gm9+uqrev7557Vx40Z973vf0/XXX6+33npL5eXlam5u1qpVq/SPf/xDbW1tuuaaa1RQUKD33ntP5eXl2rFjh/r27dvrZ09FL/edb6MDIsDQoUNNQ0ODueuuu8yhQ4eMMV/9rsDVV19tGhoazPvvv2+Sk5PNkSNHjDHGvPPOOyYjI8OcOHHC+P1+s2TJksAd2c8884xZsWKF8fv9xhhjVq9ebQoLC40xxixatMj88Y9/dLw/4Jv45AB0wu9//3tt27ZNpaWl+uyzz2SM0dmzZyVJAwcOVFJSkiSpoqJCmZmZuvTSSyVJd955p95//31JX/0K3alTp1RZWSnpq9/WSExMDEM3wLcjHIAgnT17VtOmTdOECRN0/fXXKycnR2+++abMuRlovv47CTExMYH1khQdHR147Pf7lZeXp7S0NEnS6dOn1dTU5FAXQHC4IA0EITo6WnV1dfL5fHrooYd00003aefOnWpubpbf77dtn5aWpq1bt+rUqVOSpI0bNwaeGzt2rDZs2BDY95FHHtFTTz0VGOdi+P1y9H58cgCCkJmZqcWLF2vIkCGaOHGi+vTpo6FDh+qqq65STU2N+vTpc972KSkpuu2223T77berb9++GjJkiC655BJJ0v33368nnnhCU6ZMUVtbm66++motXrxYkpSamhr4MZ45c+Y42yTwNczKCoTAv/71L+3atUszZsyQJK1fv167d+/W008/Hd7CgCARDkAI+Hw+5eXl6eDBg3K5XBo4cKCWLVum/v37h7s0ICiEAwDAhgvSAAAbwgEAYEM4AABsCAcAgA3hAACwIRwAADb/BzZkjXSoG7wLAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data=train, x=\"target\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": 1})\n",
    "output.to_csv(\"submissions/base_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In base model predictions I set all values to 1 since it is the most frequent value in our train set and after submission I got 0.5 score. It seems that one half of test data is equal to 0's and another - 1's. Let's try simple logistic regression model before diving deeper to feature engineering and more complex models. Logistic regression model improved our score by 0.13 - 0.63."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"id\", \"target\"])\n",
    "y_train = train[\"target\"]\n",
    "X_test = test.drop(columns=[\"id\"])\n",
    "\n",
    "log_reg = LogisticRegression().fit(X_train, y_train)\n",
    "predictions = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": predictions})\n",
    "output.to_csv(\"submissions/base_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"id\", \"target\"])\n",
    "y_train = train[\"target\"]\n",
    "X_test = test.drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(random_state=42, penalty=\"l1\", C=0.1, solver=\"liblinear\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.808\n"
     ]
    }
   ],
   "source": [
    "log_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"selector\", SelectFromModel(estimator=log_reg, threshold=\"2.5*mean\")),\n",
    "        (\"model\", log_reg)\n",
    "    ]\n",
    ")\n",
    " \n",
    "log_probs = cross_val_predict(log_pipe, X_train, y_train, method=\"predict_proba\")\n",
    "log_score_rt = round(roc_auc_score(y_train, log_probs[:, 1]), 3)\n",
    "print(\"Cross-validation score:\", log_score_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model__penalty\": [\"l1\"],\n",
    "    \"model__C\": [0.1],\n",
    "    \"model__solver\": [\"liblinear\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector',\n",
       "                                        SelectFromModel(estimator=LogisticRegression(random_state=42),\n",
       "                                                        threshold='2.5*mean')),\n",
       "                                       ('model',\n",
       "                                        LogisticRegression(random_state=42))]),\n",
       "             param_grid={'model__C': [0.05, 0.1, 0.2], 'model__penalty': ['l1'],\n",
       "                         'model__solver': ['liblinear']},\n",
       "             scoring=make_scorer(roc_auc_score, needs_proba=True))"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_scorer = make_scorer(roc_auc_score, greater_is_better=True, needs_proba=True)\n",
    "log_search = GridSearchCV(estimator=log_pipe, param_grid=params, scoring=roc_auc_scorer, refit=True)\n",
    "log_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__C': 0.1, 'model__penalty': 'l1', 'model__solver': 'liblinear'}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = log_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_pipe.fit(X_train, y_train)\n",
    "log_predictions = log_pipe.predict_proba(X_test)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": log_predictions[:, 1]})\n",
    "output.to_csv(\"submissions/log_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.704\n"
     ]
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "\n",
    "nb_probs = cross_val_predict(nb, X_train, y_train, method=\"predict_proba\")\n",
    "nb_score_rt = round(roc_auc_score(y_train, nb_probs[:, 1]), 3)\n",
    "print(\"Cross-validation score:\", nb_score_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb.fit(X_train, y_train)\n",
    "nb_predictions = nb.predict_proba(X_test)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": nb_predictions[:, 1]})\n",
    "output.to_csv(\"submissions/nb_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better score was achieved without hyper-parameters tuning with GridSearchCV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.719\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss=\"log\", random_state=42)\n",
    "\n",
    "sgd_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"selector\", SelectFromModel(estimator=sgd, threshold=\"2.2*mean\")),\n",
    "        (\"model\", sgd)\n",
    "    ]\n",
    ")\n",
    "\n",
    "sgd_probs = cross_val_predict(sgd_pipe, X_train, y_train, method=\"predict_proba\")\n",
    "sgd_score_rt = round(roc_auc_score(y_train, sgd_probs[:, 1]), 3)\n",
    "print(\"Cross-validation score:\", sgd_score_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    \"model__penalty\": [\"elasticnet\"],\n",
    "    \"model__l1_ratio\": [0.08],\n",
    "    \"model__max_iter\": [800]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=Pipeline(steps=[('selector',\n",
       "                                        SelectFromModel(estimator=SGDClassifier(loss='log',\n",
       "                                                                                random_state=42),\n",
       "                                                        threshold='2.2*mean')),\n",
       "                                       ('model',\n",
       "                                        SGDClassifier(loss='log',\n",
       "                                                      random_state=42))]),\n",
       "             param_grid={'model__l1_ratio': [0.08], 'model__max_iter': [800],\n",
       "                         'model__penalty': ['elasticnet']},\n",
       "             refit='roc_auc', scoring='roc_auc')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search = GridSearchCV(estimator=sgd_pipe, param_grid=params, scoring=\"roc_auc\", refit=\"roc_auc\")\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__l1_ratio': 0.08,\n",
       " 'model__max_iter': 800,\n",
       " 'model__penalty': 'elasticnet'}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = grid_search.best_params_\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_pipe.fit(X_train, y_train)\n",
    "sgd_predictions = sgd_pipe.predict_proba(X_test)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": sgd_predictions[:, 1]})\n",
    "output.to_csv(\"submissions/sgd_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest neighbors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.563\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "\n",
    "knn_probs = cross_val_predict(knn, X_train, y_train, method=\"predict_proba\")\n",
    "knn_score_rt = round(roc_auc_score(y_train, knn_probs[:, 1]), 3)\n",
    "print(\"Cross-validation score:\", knn_score_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.fit(X_train, y_train)\n",
    "knn_predictions = knn.predict_proba(X_test)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": knn_predictions[:, 1]})\n",
    "output.to_csv(\"submissions/knn_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.534\n"
     ]
    }
   ],
   "source": [
    "dtree = DecisionTreeClassifier(random_state=42)\n",
    "\n",
    "dtree_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"selector\", SelectFromModel(estimator=dtree, threshold=\"1.4*mean\")),\n",
    "        (\"model\", dtree)\n",
    "    ]\n",
    ")\n",
    "\n",
    "dtree_probs = cross_val_predict(dtree_pipe, X_train, y_train, method=\"predict_proba\")\n",
    "dtree_score_rt = round(roc_auc_score(y_train, dtree_probs[:, 1]), 3)\n",
    "print(\"Cross-validation score:\", dtree_score_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_pipe.fit(X_train, y_train)\n",
    "dtree_predictions = dtree_pipe.predict_proba(X_test)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": dtree_predictions[:, 1]})\n",
    "output.to_csv(\"submissions/dtree_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.662\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "forest_pipe = Pipeline(\n",
    "    steps=[\n",
    "        (\"selector\", SelectFromModel(estimator=forest, threshold=\"2.4*mean\")),\n",
    "        (\"model\", forest)\n",
    "    ]\n",
    ")\n",
    "\n",
    "forest_probs = cross_val_predict(forest_pipe, X_train, y_train, method=\"predict_proba\")\n",
    "forest_score_rt = round(roc_auc_score(y_train, forest_probs[:, 1]), 3)\n",
    "print(\"Cross-validation score:\", forest_score_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_pipe.fit(X_train, y_train)\n",
    "forest_predictions = forest_pipe.predict_proba(X_test)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": forest_predictions[:, 1]})\n",
    "output.to_csv(\"submissions/forest_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support vector machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation score: 0.746\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(probability=True)\n",
    "\n",
    "svm_probs = cross_val_predict(svm, X_train, y_train, method=\"predict_proba\")\n",
    "svm_score_rt = round(roc_auc_score(y_train, svm_probs[:, 1]), 3)\n",
    "print(\"Cross-validation score:\", svm_score_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm.fit(X_train, y_train)\n",
    "svm_predictions = svm.predict_proba(X_test)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": svm_predictions[:, 1]})\n",
    "output.to_csv(\"submissions/svm_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averaged predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_predictions = np.column_stack((log_predictions[:, 1], nb_predictions[:, 1], sgd_predictions[:, 1],\n",
    "                                       forest_predictions[:, 1], svm_predictions[:, 1]))\n",
    "\n",
    "averaged_predictions = stacked_predictions.mean(1).reshape(19750,)\n",
    "\n",
    "output = pd.DataFrame({\"id\": test[\"id\"], \"target\": averaged_predictions})\n",
    "output.to_csv(\"submissions/averaged_predictions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Base Score</th>\n",
       "      <th>Score</th>\n",
       "      <th>Kaggle Base Score</th>\n",
       "      <th>Kaggle Score</th>\n",
       "      <th>Real-Time Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Logistic Regression</th>\n",
       "      <td>0.74757</td>\n",
       "      <td>0.808</td>\n",
       "      <td>0.634</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>0.69792</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.591</td>\n",
       "      <td>0.661</td>\n",
       "      <td>0.704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stochastic gradient descent</th>\n",
       "      <td>0.69792</td>\n",
       "      <td>0.719</td>\n",
       "      <td>0.617</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>K-nearest neighbors</th>\n",
       "      <td>0.56267</td>\n",
       "      <td>0.563</td>\n",
       "      <td>0.543</td>\n",
       "      <td>0.561</td>\n",
       "      <td>0.563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>0.51736</td>\n",
       "      <td>0.534</td>\n",
       "      <td>0.559</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random forest</th>\n",
       "      <td>0.65295</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Support vector machine</th>\n",
       "      <td>0.75347</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.703</td>\n",
       "      <td>0.746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Averaged classifiers</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Base Score  Score  Kaggle Base Score  \\\n",
       "Logistic Regression             0.74757  0.808              0.634   \n",
       "Naive Bayes                     0.69792  0.704              0.591   \n",
       "Stochastic gradient descent     0.69792  0.719              0.617   \n",
       "K-nearest neighbors             0.56267  0.563              0.543   \n",
       "Decision Tree                   0.51736  0.534              0.559   \n",
       "Random forest                   0.65295  0.662              0.529   \n",
       "Support vector machine          0.75347  0.746              0.510   \n",
       "Averaged classifiers                NaN    NaN                NaN   \n",
       "\n",
       "                             Kaggle Score  Real-Time Score  \n",
       "Logistic Regression                 0.834            0.808  \n",
       "Naive Bayes                         0.661            0.704  \n",
       "Stochastic gradient descent         0.764            0.719  \n",
       "K-nearest neighbors                 0.561            0.563  \n",
       "Decision Tree                       0.565            0.534  \n",
       "Random forest                       0.734            0.662  \n",
       "Support vector machine              0.703            0.746  \n",
       "Averaged classifiers                0.792              NaN  "
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_base_score = 0.74757\n",
    "nb_base_score = 0.69792\n",
    "sgd_base_score = 0.69792\n",
    "knn_base_score = 0.56267\n",
    "dtree_base_score = 0.51736\n",
    "forest_base_score = 0.65295\n",
    "svm_base_score = 0.75347\n",
    "avg_base_score = None\n",
    "\n",
    "log_score = 0.808\n",
    "nb_score = 0.704\n",
    "sgd_score = 0.719\n",
    "knn_score = 0.563\n",
    "dtree_score = 0.534\n",
    "forest_score = 0.662\n",
    "svm_score = 0.746\n",
    "avg_score = None\n",
    "\n",
    "kaggle_base_log_score = 0.634\n",
    "kaggle_base_nb_score = 0.591\n",
    "kaggle_base_sgd_score = 0.617\n",
    "kaggle_base_knn_score = 0.543\n",
    "kaggle_base_dtree_score = 0.559\n",
    "kaggle_base_forest_score = 0.529\n",
    "kaggle_base_svm_score = 0.510\n",
    "kaggle_base_avg_score = None\n",
    "\n",
    "kaggle_log_score = 0.834\n",
    "kaggle_nb_score = 0.661\n",
    "kaggle_sgd_score = 0.764\n",
    "kaggle_knn_score = 0.561\n",
    "kaggle_dtree_score = 0.565\n",
    "kaggle_forest_score = 0.734\n",
    "kaggle_svm_score = 0.703\n",
    "kaggle_avg_score = 0.792\n",
    "\n",
    "scores_table = pd.DataFrame({\"Base Score\": [log_base_score, nb_base_score, sgd_base_score, knn_base_score, dtree_base_score,\n",
    "                                            forest_base_score, svm_base_score, avg_base_score],\n",
    "                             \"Score\": [log_score, nb_score, sgd_score, knn_score, dtree_score, forest_score, svm_score, avg_score],\n",
    "                             \"Kaggle Base Score\": [kaggle_base_log_score, kaggle_base_nb_score, kaggle_base_sgd_score, kaggle_base_knn_score, kaggle_base_dtree_score, \n",
    "                                                   kaggle_base_forest_score, kaggle_base_svm_score, kaggle_base_avg_score],\n",
    "                             \"Kaggle Score\": [kaggle_log_score, kaggle_nb_score, kaggle_sgd_score, kaggle_knn_score, kaggle_dtree_score,\n",
    "                                              kaggle_forest_score, kaggle_svm_score, kaggle_avg_score],\n",
    "                             \"Real-Time Score\": [log_score_rt, nb_score_rt, sgd_score_rt, knn_score_rt, dtree_score_rt, forest_score_rt,\n",
    "                                                 svm_score_rt, None]\n",
    "                             }\n",
    "                            ).set_axis(\n",
    "                                 [\"Logistic Regression\", \"Naive Bayes\", \"Stochastic gradient descent\", \"K-nearest neighbors\", \n",
    "                                  \"Decision Tree\", \"Random forest\", \"Support vector machine\", \"Averaged classifiers\"], axis=\"index\"\n",
    "                                 )\n",
    "                             \n",
    "scores_table"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0704b5f16a1388f986ccaeadcccf8c1c9a876b02e39bf3eec2c267b2b75455d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
